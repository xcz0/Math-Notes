# 动作价值方程

由于 $G_t=R_{t+1}+\gamma G_{t+1}$，所以：
$$\begin{aligned}
q_{\pi}(s,a)& =\mathbb{E}[G_t|S_t=s,A_t=a] \\
&=\mathbb{E}[R_{t+1}+\gamma G_{t+1}|S_t=s,A_t=a] \\
&=\mathbb{E}[R_{t+1}|S_t=s,A_t=a]+\gamma\mathbb{E}[G_{t+1}|S_t=s,A_t=a]
\end{aligned}$$
即动作价值可拆分为即时回报加上衰减的未来回报。
+ 即时回报为：$\mathbb{E}[R_{t+1}|S_t=s,A_t=a]=\sum_{r \in \mathcal{R}}p(r|s,a)r$
+ 未来回报为：$\mathbb{E}[G_{t+1}|S_t=s,A_t=a]=\sum_{s' \in \mathcal{S}}p(s'|s,a)v_{\pi}(s')$
得到动作价值：
$$ q_{\pi}(s,a)=\sum_{r \in \mathcal{R}}p(r|s,a)r+ \gamma \sum_{s' \in \mathcal{S}}p(s'|s,a)v_{\pi}(s')$$

根据动作价值函数与状态价值的关系：$v_{\pi}(s)=\sum_{a \in \mathcal{A}}q_\pi(s,a) \pi(a|s)$，这也与[[状态价值方程]]吻合。

将状态价值用动作价值替代后得：
$$q_\pi(s,a)=\sum_{r\in\mathcal{R}}p(r|s,a)r+\gamma\sum_{s'\in\mathcal{S}}p(s'|s,a)\sum_{a'\in\mathcal{A}}\pi(a'|s')q_\pi(s',a')$$
矩阵形式为：
$$ Q_{\pi}=R+\gamma P \Pi Q_{\pi} $$
其中：
+ $Q_{\pi}$ 为状态价值*向量*，维度为 $(|\mathcal{S}| \times |\mathcal{A}|) \times 1$， 第 $(s,a)$ 项为 $q_{\pi}(s,a)$
+ $R$ 为即时奖励的期望*向量*，维度为 $(|\mathcal{S}| \times |\mathcal{A}|) \times 1$， 第 $(s,a)$ 项为 $\mathbb{E}[R_{t+1}|S_t=s,A_t=a]$
+ $\mathbf{P}$ 为状态转移概率矩阵,维度为 $(|\mathcal{S}| \times |\mathcal{A}|) \times |\mathcal{S}|$，第 $[(s,a),s']$ 项为 $p(s'|s,a)$
+ $\mathbf{\Pi}$ 为策略矩阵块对角矩阵，维度为 $|\mathcal{S}| \times (|\mathcal{S}| \times |\mathcal{A}|)$，每个块是一个 $1 \times |\mathcal{A}|$ 的行向量，表示在状态 $i$ 下所有动作的概率分布 $\pi(a_j,s_i)$。
$$\mathbf{\Pi} = \begin{bmatrix} 
\pi_1 & \mathbf{0} & \cdots & \mathbf{0} \\
\mathbf{0} & \pi_2 & \cdots & \mathbf{0} \\
\vdots & \vdots & \ddots & \vdots \\
\mathbf{0} & \mathbf{0} & \cdots & \pi_{|\mathcal{S}|}
\end{bmatrix}$$


