# 状态价值

状态价值：从特定状态出发，依特定策略获得的回报。

考虑单步过程：
$$S_t\xrightarrow{A_t}R_{t+1},S_{t+1}$$ 皆为随机变量，其中
+ $S_t \to A_t$ 由策略 $\pi(A_t=a|S_t=s)$ 描述
+ $S_t,A_t \to S_{t+1}$ 由动作模型 $p(S_{t+1}=s'|S_t=s,A_t=a)$ 描述
+ $S_t,A_t \to R_{t+1}$ 由奖励模型 $p(R_{t+1}=r|S_t=s,A_t=a)$ 描述

对于多步轨迹：
$$S_t\xrightarrow{A_t}R_{t+1},S_{t+1}\xrightarrow{A_{t+1}}R_{t+2},S_{t+2}\xrightarrow{A_{t+2}}R_{t+3},\ldots $$
其折扣回报为
$$G_t=R_{t+1}+\gamma R_{t+2}+\gamma^2R_{t+3}+\ldots $$ 
>随机变量 $G_t$ 虽然受 $S_t$ 取值的影响，但其直接定义与 $S_t$ 无关，仅与 $t$ 相关

其期望定义为状态价值函数
$$ v_\pi(s)=\mathbb{E}[G_t|S_t=s]$$
当所有模型为决定性而非随机的，状态价值即为回报。


## 状态价值方程

由于
$$\begin{align}
G_t& =R_{t+1}+\gamma R_{t+2}+\gamma^2R_{t+3}+\ldots \\
&=R_{t+1}+\gamma(R_{t+2}+\gamma R_{t+3}+\ldots) \\
&=R_{t+1}+\gamma G_{t+1}
\end{align}$$
故
$$\begin{aligned}
v_{\pi}(s)& =\mathbb{E}[G_t|S_t=s] \\
&=\mathbb{E}[R_{t+1}+\gamma G_{t+1}|S_t=s] \\
&=\mathbb{E}[R_{t+1}|S_t=s]+\gamma\mathbb{E}[G_{t+1}|S_t=s]
\end{aligned}$$
即状态价值可拆分为即时回报加上衰减的未来回报。



其中即时奖励的均值为：
$$\begin{aligned}
\mathbb{E}[R_{t+1}|S_{t}=s]& =\sum_a\pi(a|s)\mathbb{E}[R_{t+1}|S_t=s,A_t=a] \\
&=\sum_a\pi(a|s)\sum_rp(r|s,a)r
\end{aligned}$$

未来回报的均值为：
$$\begin{aligned}
\mathbb{E}[G_{t+1}|S_{t}=s]& =\sum_{s'}\mathbb{E}[G_{t+1}|S_t=s,S_{t+1}=s']p(s'|s) \\
&=\sum_{s'}\mathbb{E}[G_{t+1}|S_{t+1}=s']p(s'|s) \\
&=\sum_{s'}v_\pi(s')p(s'|s) \\
&=\sum_{s'}v_\pi(s')\sum_ap(s'|s,a)\pi(a|s)
\end{aligned}$$
注意第二步使用了无记忆性。

综合：
$$\begin{align}
v_{\pi}(s) & = \mathbb{E}[R_{t+1}|S_t=s]+\gamma\mathbb{E}[G_{t+1}|S_t=s] \\
&= \sum_a\pi(a|s)\sum_rp(r|s,a)r + \gamma \sum_a\pi(a|s)\sum_{s'}p(s'|s,a)v_\pi(s') \\
&= \sum_a\pi(a|s)\left[\sum_rp(r|s,a)r + \gamma \sum_{s'}p(s'|s,a)v_\pi(s') \right]
\end{align}$$
称此为**Bellman方程**。若环境模型 $p(r|s,a),p(s'|s,a)$ 是确定的，则此状态函数只与策略 $\pi(a|s)$ 相关，求解此方程称为策略评估。

## 状态价值方程求解

记
$$r_\pi(s)\triangleq\sum_a\pi(a|s)\sum_rp(r|s,a)r,\quad p_\pi(s'|s)\triangleq\sum_a\pi(a|s)p(s'|s,a)$$
则原方程可改写为
$$v_\pi(s)=r_\pi(s)+\gamma\sum_{s'}p_\pi(s'|s)v_\pi(s')$$
将其改写为矩阵形式
$$ \mathbf{v}_{\pi}=\mathbf{r}_{\pi}+\gamma P_{\pi}\mathbf{v}_{\pi} $$
其中
$$\begin{align}
v_{\pi}&=[v_{\pi}(s_{1}),\ldots,v_{\pi}(s_{n})]^{T} \\
r_{\pi}&=[r_{\pi}(s_{1}),\ldots,r_{\pi}(s_{n})]^{T} \\
[P_\pi]_{ij}&=p_\pi(s_j|s_i)
\end{align}$$

