# Bellman最优方程

在相同的状态下，若一个策略能获得的状态价值比另一个的大，则认为这个策略更好。故最优策略定义为能使状态函数最大的策略。

若对于状态空间中的所有状态 $s \in \mathcal{S}$，基于策略 $\pi^*$ 的状态价值 $v_{\pi^*}(s)$ 不低于其他策略下的，则称其为**最优策略**， $v_{\pi^*}(s)$ 为最优状态价值。

> 在[[无记忆决策过程]]的框架下，最优策略只受当前的状态影响（否则前几个时刻的状态也会产生影响），故可以针对状态空间中的所有状态定义最优策略，而不会冲突。

## 最优策略的形式

若状态与动作都是有限的，则必然存在奖励最高的组合 $r(s,a)$（可以不唯一），其最优策略即为此动作，并且最优价值为。此时，对于其周围的状态（能够通过某个动作到达，即 $p(s|s',a)>0$）