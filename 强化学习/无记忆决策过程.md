# 无记忆决策过程(Markov decision process ,MDP)

在马尔可夫决策过程中，下一个状态只依赖于前一个状态与动作，由状态转移概率函数 $P(s'|s, a)$ 表示。下一个奖励依赖于前一个状态与动作，由奖励函数 $r(s, a)$ 表示。强化学习的马尔可夫决策过程是状态、奖励、动作序列上的随机过程，由五元组 $<S,A,P,r,\gamma>$ 组成。
+ $S$ 是有限状态 (state) 的集合
+ $A$ 是有限动作 (action) 的集合
+ $P$ 是状态转移概率 (transition probability) 函数：
$$\begin{align}
p(s_{t+1}|a_t,s_t,\ldots,a_0,s_0)=p(s_{t+1}|a_t,s_t) \\
p(r_{t+1}|a_t,s_t,\ldots,a_0,s_0)=p(r_{t+1}|a_t,s_t)
\end{align}$$
+ $r$ 是奖励函数 (reward function)： $r(s, a) = E(r_{t+1}|s_t = s, a_t = a)$
+ $\gamma$ 是衰减系数 (discount factor)：$\gamma \in [0,1]$

