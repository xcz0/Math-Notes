# 条件熵

条件熵 $H(Y|X)$ 表示在已知随机变量 $X$ 的条件下随机变量 $Y$ 的不确定性。

随机变量 $X$ 给定的条件下，随机变量 $Y$ 的**条件熵** (conditional entropy) 定义为 X 给定条件下 Y 的条件概率分布的[[熵]]对 $X$ 的数学期望：
$$ H(Y|X)=E_{X}[H(Y|X)]=\sum_{i=1}^{n}H(Y|X=x_i)P(X=x_i)  $$

当墒和条件熵中的概率由数据估计（特别是极大似然估计）得到时，所对应的墒与条件熵分别称为**经验熵**(empirical entropy) 和**经验条件熵**(empirical conditional entropy) 。一般地，熵 $H(Y)$ 与条件熵 $H(Y|X)$ 之差称为**互信息** (mutual information) 。
