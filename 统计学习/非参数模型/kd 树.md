# kd 树

kd 树是一种对 K 维空间中的实例点进行存储以便对其进行快速检索的树形数据结构。 kd 树相当于 K 维空间中的二分查找树(Binary Search Tree，BST)，每个节点判断的数值来自于不同的维度。

![[Pasted image 20230219163512.png]]

![[Pasted image 20230219163525.png]]

### 构造 kd 树

>[!tip] 构造平衡 kd 树
>输入：$K$ 维空间数据集 $T = \{x_1, x_{2},\cdots,x_{N}\}$
>输出：kd 树
>1. 构造根结点：
>2. 选取方差最大的特征作为分割特征；
>3. 选择该特征的中位数作为分割点；
>4. 将数据集中该特征小于中位数的传递给根节点的左儿子，大于中位数的传递给根节点的右儿子；
>5. 递归执行步骤2-4，直到所有数据都被建立到KD Tree的节点上为止。

您可能还会问，为什么方差最大的适合作为特征呢？ 因为方差大，数据相对“分散”，选取该特征来对数据集进行分割，数据散得更“开”一些。您可能又要问，为什么选择中位数作为分割点呢？ 因为借鉴了BST，选取中位数，让左子树和右子树的数据数量一致，便于二分查找。

### 搜索 kd 树

>[!tip] kd 树的最近邻搜索
>输入：已构造的 kd 树，目标点 $x$;
>输出：$x$ 的最近邻。
>1. 从根节点开始，根据目标在分割特征中是否小于或大于当前节点，向左或向右移动：
>2. 一旦算法到达叶节点，它就将节点点保存为“当前最佳”；
>3. 回溯，即从叶节点再返回到根节点；
>4. 如果当前节点比当前最佳节点更接近，那么它就成为当前最好的；
>5. 如果目标距离当前节点的父节点所在的将数据集分割为两份的超平面的距离更接近，说明当前节点的兄弟节点所在的子树有可能包含更近的点。因此需要对这个兄弟节点递归执行1-4步。