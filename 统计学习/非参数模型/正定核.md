# 正定核

非参数模型的关键在于衡量数据点间的*相似度*，以便在遇到新的数据点时，能使用与之接近的已知数据点预测。一般在线性模型中，直接使用数据点的


使用核函数表示和学习非线性模型的一种机器学习方法。有一些线性模型的学习方法基于*相似度*计算，即向量内积计算。核方法可以把它们扩展到非线性模型的学习，使其应用范围更广泛。

把线性模型扩展到非线性模型，直接的做法是显式地定义从输入空间（低维空间）到特征空间（高维空间）的映射，在特征空间中进行内积计算。核方法的技巧在于不显式地定义这个映射，而是直接定义核函数，即映射之后在特征空间的内积。这样可以简化计算，达到同样的效果。

假设 $x_1$ 和 $x_2$ 是输入空间的任意两个实例（向量），其内积是 $<x_1,x_2>$。假设从输入空间到特征空间的映射是 $\phi$，即 $x_1$ 和 $x_2$ 在特征空间的映像是 $\phi(x_1)$ 和 $\phi(x_2)$，其内积是 $<\phi(x_1), \phi(x_1)>$。核方法直接在输入空间中定义核函数 $K(x_1, x_2)$，使其满足 $K(x_1, x_2)=<\phi(x_1), \phi(x_1)>$。