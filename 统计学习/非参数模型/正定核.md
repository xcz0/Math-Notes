# 正定核

非参数模型的关键在于衡量数据点间的*相似度*，以便在遇到新的数据点时，能使用与之接近的已知数据点预测。类似于[[度量]]的概念，为相似度 $\mathcal{K}(x,y)$ 设定两个基础的要求：
+ 非负性：相似度必须大于零 $\mathcal{K}(x,y)\geq 0$
+ 对称性：两点间的相似度与位置无关 $\mathcal{K}(x,y)=\mathcal{K}(y,x)$

在此基础上，若Gram矩阵：
$$\mathbf{K}=\begin{pmatrix}\mathcal{K}(\boldsymbol{x}_1,\boldsymbol{x}_1)&\cdots&\mathcal{K}(\boldsymbol{x}_1,\boldsymbol{x}_N)\\&\vdots\\\mathcal{K}(\boldsymbol{x}_N,\boldsymbol{x}_1)&\cdots&\mathcal{K}(\boldsymbol{x}_N,\boldsymbol{x}_N)\end{pmatrix}$$
对于任意数据点都是一个[[正定矩阵]]，则将其中 $\mathcal{K}(x,y)$ 称为**正定核**(positive definite kernel)。

最常见的正定核为squared exponential kernel (SE),
also called the exponentiated quadratic kernel (EQ), Gaussian kernel, or RBF kernel，定义为：
$$\mathcal{K}(x,y)=\exp\left(-\frac{||x-y||^2}{2\ell^2}\right)$$

由于Gram矩阵 $\mathcal{K}$ 为实对称矩阵，故可进行[[特征值分解]]：$\mathbf{K}=\mathbf{U}^{\mathsf{T}}\mathbf{\Lambda}\mathbf{U}$，其中 $\mathbf{U}$ 为由其特征值组成；$\Lambda$ 为特征值对角矩阵，并且由于Gram矩阵正定，故其各元素皆大于零。

由于
$$ \mathbf{K}=\mathbf{U}^{\mathsf{T}}\mathbf{\Lambda}\mathbf{U}=\mathbf{K}= \mathbf{\Lambda}^{1 / 2}\mathbf{U}=\left( \mathbf{\Lambda}^{1 / 2}\mathbf{U} \right)^{\mathsf{T}}\left( \mathbf{\Lambda}^{1 / 2}\mathbf{U} \right)   $$
故矩阵中的元素为：$k_{i,j}=(\mathbf{\Lambda}^{1 / 2}u_i)^\mathsf{T} (\mathbf{\Lambda}^{1 / 2}u_i)$，其中 $u_i$ 为 $\mathbf{U}$ 的第 $i$ 个列向量。再定义 $\phi(x_i)=\mathbf{\Lambda}^{1 / 2}u_i$，则
$$\mathcal{K}(\boldsymbol{x}_i,\boldsymbol{x}_j)=k_{ij}=\phi(\boldsymbol{x}_i)^\mathsf{T}\phi(\boldsymbol{x}_j)$$
即正定核函数可视为数据点经映射 $\phi$ 后的内积。

例


