# 监督学习

给定的数据集中包含输入以及标记好的输出（标签）。

+ 回归：输出的数据范围为“连续”的区间，如房价预测、温度预测等。
+ 分类：输出只在有限个类别中，如物体识别、邮件分类等。
+ 搜索、推荐系统：输出为序的元素⼦集，用于对⼀组项⽬进⾏排序，例如信息检索排序、商品推荐。
+ 序列学习：输出不仅仅由单一对应的输入给定，还与之前的输入有关，即模型需要有“记忆性”，例如：语言处理、医学监控。
+ 结构化学习：输出有结构性的数据，例如文本、

在监督学习中，任务$T$是学习从输入$x \in \mathcal{X}$到输出$y \in \mathcal{Y}$的映射。输入$x$又称自变量(independnt varible)，预测因素(predictors)，特征(features)，协变量(covariates)，有时也直接简称为变量(varible)。输入通常是一个固定维数的数值向量，即$\mathcal{X} = \mathbb{R}^D$，其中$D$是向量维数（或输入特征数）。输出$y$是又称因变量(dependnt varible)，标签(label)，响应(response) ，目标(target)。
> 有时（例如，在[statsmodel](https://www.statsmodels.org/devel/endog_exog.html) Python 包中） $x$ 被称为外生变量，$y$ 被称为内生变量。

经验$E$是$N$个输入输出对$\mathcal{D}=\{ (x_n,y_n) \}^N_{n=1}$，即训练数据，$N$称为样本容量(sample size)。

性能指标 $P$ 取决于我们预测的输出类型，由此区分为了以下问题。

## 分类

在分类问题中，输出空间是C个无序且互斥的标签，称为类，$\mathcal{Y} = \{ 1,2,\cdots,C \}$。在给定输入的情况下预测类标签的问题也称为模式识别(pattern recognition)。若仅由两个类别，通常记为$y \in \{ 0, 1 \}$或$y \in \{ -1, +1 \}$，称为二分类(binary classification)问题。

### 数据储存

对于小型特征数据集，通常将它们存储在一个 $N \times D$ 维矩阵中，其中每行代表一个示例，每列代表一个特征。这称为设计矩阵(design matrix)。当输入的大小可变（例如，单词序列或社交网络）而不是固定长度的向量时，数据通常以其他格式存储，而不是设计矩阵。但是，此类数据通常会转换为固定大小的特征表示（此过程称为特征化(featurization)），从而隐式创建设计矩阵以供进一步处理。

### 数据探索

在解决机器学习的问题之前，最好先进行探索性数据分析(exploratory data analysis)，看看有没有明显的模式(这可能会提示我们选择哪种方法) ，或者数据有没有明显的问题(例如标签噪音或异常值)。

对于特征数量较少的表格数据，通常制作成对图(pair plot)，其中面板 $(i,j)$ 显示变量 $i$ 和 $j$ 的散点图，对角线条目 $(i,i)$ 显示变量 $i$ 的边际密度，所有图都可以选择按类标签进行颜色编码。

监督学习(supervised learning) 是指从标注数据中学习预测模型的机器学习问
题。监督学习的本质是学习输入到输出的映射的统计规律。监督学习假设统计学习假设数据存在一定的统计规律：输入与输出的随机变量 $X$ 和 $Y$ 遵循联合概率分布 $P(X,Y)$ 。$P(X,Y)$ 表示分布函数，或分布密度函数。训练数据与测试数据被看作是依联合概率分布 $P(X,Y)$ 独立同分布产生的。

+ 回归问题：输入变量与输出变量均为连续变量；
+ 分类问题：输出变量为有限个离散变量；
+ 标注问题：输入变量与输出变量均为变量序列。

##### 输入空间、特征空间和输出空间

输入与输出所有可能取值的集合分别称为输入空间(input space) 与输出空间 (output space) 。通常输出空间远远小于输入空间。每个具体的输入是一个实例 (instance) ，通常由特征向量 (feature vector) 表示。这时，所有特征向最存在的空间称为特征空间 (feature space) 。

在监督学习中，将输入与输出看作是定义在输入（特征）空间与输出空间上的随机变量的取值。输入实例 $x$ 的特征向量记作
$$x = (x^{(1)}, \cdots, x^{(i)}, \cdots, x^{(n)})^{T}$$   

 监督学习从训练数据 (training data) 集合中学习模型，对测试数据
(test data)进行预测。

##### 假设空间与模型

监督学习的目的在于找到最好的由输入到输出的映射模型。模型属于由输入空间到输出空间的映射的集合，这个集合就是假设空间(hypothesis space) 。假设空间的确定意味着学习的范围的确定。

模型可以是概率模型或非概率模型，由条件概率分布 $P(Y|X)$ 或决策函数(decisionfunction) $Y = f (X)$ 表示。对具体的输入进行相应的输出预测时，写作 $P(y l x)$ 或 $y = f(x)$。

![[Pasted image 20230214211126.png]]

## 半监督学习

半监督学习(semi-supervised learning) 是指利用标注数据和未标注数据学习预测模型的机器学习问题。通常有少量标注数据、大量未标注数据。半监督学习旨在利用未标注数据中的信息，辅助标注数据，进行监督学习，以较低的成本达到较好的学习效果。

