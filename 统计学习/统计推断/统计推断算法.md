# 统计推断算法

将模型中的所有未知量：预测结果、系统隐藏状态、模型参数，都作为随机变量处理。通过已知数据得出这些量的后验分布并依此计算的过程称为**推断**(inference)。

一般用 $\theta$ 代表未知变量，用 $\mathcal{D}$ 代表已知变量。未知变量的后验分布为：
$$ p(\theta|\mathcal{D})=\frac{p(\theta)p(\mathcal{D}|\theta)}{p(\mathcal{D})} $$

归一化常数：
$$ p(\mathcal{D})=\int p(\mathcal{D}|\theta)p(\theta) \, d\theta  $$
是主要的计算难点，因为未知参数的维度可能很高。

常用的计算方式有：
#TODO 


当获得后验分布后，即可计算感兴趣的后验期望
$$\mathbb{E}\left[g(\theta)|\mathcal{D}\right]=\int g(\boldsymbol{\theta})p(\boldsymbol{\theta}|\mathcal{D})d\boldsymbol{\theta}$$
其中函数 $g$ 的选取包括：
+ 均值：$g(\boldsymbol{\theta})=\boldsymbol{\theta}$
+ 方差：$g(\boldsymbol{\theta})=(\boldsymbol{\theta}-\mathbb{E}\left[\boldsymbol{\theta}|\mathcal{D}\right])(\boldsymbol{\theta}-\mathbb{E}\left[\boldsymbol{\theta}|\mathcal{D}\right])^\mathsf{T}$
+ 边际分布：$g(\boldsymbol{\theta})=p(\theta_{1}=\theta_{1}^{*}|\boldsymbol{\theta}_{2:D})$
+ 预测：$g(\boldsymbol{\theta})=p(\boldsymbol{y}_{N+1}|\boldsymbol{\theta})$
+ 期望损失：$g(\boldsymbol\theta)=\ell(\boldsymbol\theta,a)$
+ 模型的似然函数：$g(\boldsymbol{\theta})=p(\mathcal{D}|\boldsymbol{\theta},M)$，此时模型的边际似然可写为
$$\mathbb{E}\left[g(\boldsymbol{\theta})|M\right]=\int g(\boldsymbol{\theta})p(\boldsymbol{\theta}|M)d\boldsymbol{\theta}=\int p(\mathcal{D}|\boldsymbol{\theta},M)p(\boldsymbol{\theta}|M)d\boldsymbol{\theta}=p(\mathcal{D}|M)$$

## 推断模式

### 全局隐变量

未知变量对所有训练数据皆有影响，但独立于其他变量，例如模型参数，其联合分布为：
$$ p(Y,\theta|X)=p(Y|X,\theta)p(\theta|X)=p(\theta)\prod_{i=1}^{N}p(y_i|x_{i},\theta) $$
推断目标为 $p(\theta|X,Y)$。
![[全局隐变量.png]]

### 局部隐变量

未知变量只对部分已知变量产生影响，例如模型的隐藏状态，影响其他输出，但对参数无影响，其联合分布为：
$$p(\boldsymbol{x}_{1:N},\boldsymbol{z}_{1:N}|\boldsymbol{\theta})=\left[\prod_{n=1}^Np(\boldsymbol{x}_n|\boldsymbol{z}_n,\boldsymbol{\theta}_x)p(\boldsymbol{z}_n|\boldsymbol{\theta}_z)\right]$$
推断目标为 $p(z|x,\theta)$。
![[局部隐变量.png]]


若模型参数已知，常使用[[概率图模型]]推断方法。

若模型参数未知，常使用[[隐变量模型]]，常使用[[期望最大化(EM)算法]]计算后验分布。

### 全局与局部隐变量

未知变量既包含全局隐变量，也包含局部隐变量，其联合分布为：
$$p(\boldsymbol{x}_{1:N},\boldsymbol{z}_{1:N},\boldsymbol{\theta})=p(\boldsymbol{\theta}_x)p(\boldsymbol{\theta}_z)\left[\prod_{n=1}^Np(\boldsymbol{x}_n|\boldsymbol{z}_n,\boldsymbol{\theta}_x)p(\boldsymbol{z}_n|\boldsymbol{\theta}_z)\right]$$
![[全局与局部隐变量.png]]


## 准确推断算法

若先验分布与似然函数为[[共轭分布]]，则其后验分布易得。例如，若皆为[[指数分布族]]：
$$\begin{aligned}p(\boldsymbol{\theta})&\propto\exp(\boldsymbol{\lambda}_0^\mathsf{T}\mathcal{T}(\boldsymbol{\theta}))\\p(\boldsymbol{y}_i|\boldsymbol{\theta})&\propto\exp(\tilde{\boldsymbol{\lambda}}_i(\boldsymbol{y}_i)^\mathsf{T}\mathcal{T}(\boldsymbol{\theta}))\end{aligned}$$
则其后验分布为：
$$\begin{align}
p(\boldsymbol{\theta}|\boldsymbol{y}_{1:N})&=\exp(\boldsymbol{\lambda}_*^\mathsf{T}\mathcal{T}(\boldsymbol{\theta}))\\ 
\lambda_* &=\lambda_0+\sum_{n=1}^N\tilde{\boldsymbol{\lambda}}_n(\boldsymbol{y}_n)
\end{align}$$

## 近似推断算法

### 最大后验估计近似

在获得未知量的最大后验估计后，
$$\hat{\boldsymbol{\theta}}=\operatorname{argmax}p(\boldsymbol{\theta}|\mathcal{D})=\operatorname{argmax}\operatorname{log}p(\boldsymbol{\theta})+\operatorname{log}p(\mathcal{D}|\boldsymbol{\theta}) $$
直接将其视为常数 $p(\boldsymbol{\theta}|\mathcal{D})\approx\delta(\boldsymbol{\theta}-\hat{\boldsymbol{\theta}})$，代替后验分布计算期望。

然而，这个近似有一些问题：
+ 将分布简化为了常数，无法计算其标准差和[[可信区间]]。也会低估预测结果的不准确性。
+ 概率密度峰值有时与整体分布相差很远，尤其对于多峰分布与偏态分布
+ 有时需要将此变量转化为另一变量再计算，将其作为常数会极大误导后续计算。

### 网格近似

将未知量的定义域划分为大小为 $\Delta$ 网格区间 $\boldsymbol{r}_{1},\ldots,\boldsymbol{r}_{K}$，用未知量在区间的中点 $\boldsymbol{\theta}_{k}$ 的概率近似代替整个区间的概率：
$$p(\boldsymbol{\theta}\in\boldsymbol{r}_{k}|\mathcal{D})\approx p_{k}\Delta $$
其中
$$\begin{aligned}&p_{k}=\frac{\tilde{p}_{k}}{\sum_{k'=1}^{K}\tilde{p}_{k'}}\\&\tilde{p}_{k}=p(\mathcal{D}|\boldsymbol{\theta}_{k})p(\boldsymbol{\theta}_{k})\end{aligned}$$
此时归一化参数近似为：
$$p(\mathcal{D})=\int p(\mathcal{D}|\boldsymbol{\theta})p(\boldsymbol{\theta})d\boldsymbol{\theta}\approx\sum_{k=1}^K\Delta\tilde{p}_k$$

例：



此方法的优点在于随着区域划分得越密集，对后验分布的近似将越准确。然后这也将导致计算量增加，尤其是对于高维分布，将呈指数级增长。


### 二次近似

### 变分推断

### Markov链随机模拟

### 序列随机模拟

## 近似推断算法的评估

若真实分布已知，则通过对比近似结果与真实分布的差异，评价近似方法，使用的方法例如：[[KL散度]] 、[[Wasserstein距离]]。若近似方法需要迭代，也可通过迭代结果的相似度变换来分析其收敛速度。

若真实分布未知，则将近似结果代入后的计算结果与可观测的结果对比，常用的有期望损失或Bayes风险。

