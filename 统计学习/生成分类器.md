# 生成分类器

设输入空间 $\mathcal{X} \subseteq \mathbb{R}^n$ 为 $n$ 维向量的集合，输出空间为类标记集合 $\mathcal{y} =\{ c_{1},\cdots,c_{K} \}$。输入为特征向量 $x \in \mathcal{X}$，输出为类标记 $y \in \mathcal{Y}$。$X$ 是定义在输入空间 $\mathcal{X}$ 上的随机向量，$Y$ 是定义在输出空间 $\mathcal{Y}$ 上的随机变量。$P(X,Y)$ 是 $X$ 和 $Y$ 的联合概率分布。训练数据集
$$ T=\{ (x_{1},y_{1}),\cdots , (x_{N},y_{N})\} $$
由 $P(X,Y)$ *独立同分布*产生。

从概率视角，分类器即是在已知样本特征 $x$ 下，找到特定的类别 $c$ ，使得 $p(y=c|\boldsymbol{x},\boldsymbol{\theta})$ 最大，从而将此样本分类为 $c$ 。

根据Bayes公式，将 $p(y=c|\boldsymbol{x},\boldsymbol{\theta})$ 拆解为：
$$ p(y=c|\boldsymbol{x},\boldsymbol{\theta})=\frac{p(\boldsymbol{x}|y=c,\boldsymbol{\theta})p(y=c|\boldsymbol{\theta})}{\sum_{c'}p(\boldsymbol{x}|y=c',\boldsymbol{\theta})p(y=c'|\boldsymbol{\theta})} $$
其中，$p(y=c|\boldsymbol{\theta})$ 代表各类别的先验概率；$p(\boldsymbol{x}|y=c,\boldsymbol{\theta})$ 是类别 $c$ 的**类条件密度**(class-conditional density)，被视为模型参数；$p(\boldsymbol{x}|\boldsymbol{\theta})=\sum_{c'}p(\boldsymbol{x}|y=c',\boldsymbol{\theta})p(y=c'|\boldsymbol{\theta})$ 是归一化因子。

由于此模型可通过由 $p(\boldsymbol{x}|y=c,\boldsymbol{\theta})$ 采样，为特征 $\boldsymbol{x}$ 生成类别，故称之为**生成分类器**(generative classifier)。

一般而言，假设训练集中的样本都是独立同分布的，由大数定律可知，当训练集较大时，即可用各类样本出现的频率估计 $p(y=c|\boldsymbol{\theta})$ 。同时，$p(\boldsymbol{x}|\boldsymbol{\theta})$ 与类别无关。所以，此模型的重点问题就是如何通过训练数据估计类条件密度 $p(\boldsymbol{x}|y=c,\boldsymbol{\theta})$ 。

对于类条件概率 $p(\boldsymbol{x}|y=c,\boldsymbol{\theta})$ 而言，一般不能直接根据样本出现的频率来估计。因为样本属性的取值有可能是连续的，其取值空间是无限的。即使将其分段截取，或本来就只能取离散值，其取值空间的大小也是呈指数增长的，往往远大于训练样本数量。这称之为组合爆炸、样本稀疏问题。此时用频率估计概率是很不合理的。


