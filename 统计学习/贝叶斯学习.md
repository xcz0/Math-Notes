# 贝叶斯学习(Bayesian learning)

利用贝叶斯定理，计算在给定数据条件下模型的条件概率，即后验概率，并应用这个原理进行模型的估计，以及对数据的预测。

假设随机变量 $D$ 表示数据，随机变量 $\theta$ 表示模型参数。根据贝叶斯定理，可以用后验概率为：
$$P(\theta|D)=\frac{P(\theta)P(D|\theta)}{P(D)}=\frac{P(\theta)P(D|\theta)}{\int P(D|\theta) P(\theta) d \theta}$$
预测时，计算新样本 $x$ 对后验概率分布的期望值：
$$P(x|D)=\int P(x|\theta,D)P(D|\theta))d \theta$$

假设先验分布是均匀分布，此时 $P(\theta)$ 为常数，$P(D)$ 与 $\theta$ 无关，取后验概率最大，就能从贝叶斯估计得到极大似然估计
$$\hat{\theta}=\max_{\theta}P(D|\theta)$$


## 贝叶斯分类器

数学上可以证明，使得测试错误率最小的，是一类非常简单的分类器：在已知自变量值的前提下，将最有可能的类，分配给每一个测试数据。即：已知自变量为 �0 将 � 分配给每一个测试数据， � 是使得如下条件概率最大的类

��(�=�|�=�0)

这就是贝叶斯分类器(Bayes classifier)  
用贝叶斯分类器得到的测试错误率称作贝叶斯错误率(Bayes error rate)：

1−�(max���(�=�|�))