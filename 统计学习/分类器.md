# 分类器

从概率视角，分类器即是在已知样本特征 $x$ 下，找到特定的类别 $c$ ，使得 $p(y=c|\boldsymbol{x},\boldsymbol{\theta})$ 最大，从而将此样本分类为 $c$ 。根据 $p(y=c|\boldsymbol{x},\boldsymbol{\theta})$ 不同的确定方式，分类器也分为两种：

## 判别分类器

若直接通过训练数据确定 $p(y|x,\theta)$，则称之为**判别分类器**(discriminative classifier)。

## 生成分类器

根据Bayes公式，将 $p(y=c|\boldsymbol{x},\boldsymbol{\theta})$ 拆解为：
$$ p(y=c|\boldsymbol{x},\boldsymbol{\theta})=\frac{p(\boldsymbol{x}|y=c,\boldsymbol{\theta})p(y=c|\boldsymbol{\theta})}{\sum_{c'}p(\boldsymbol{x}|y=c',\boldsymbol{\theta})p(y=c'|\boldsymbol{\theta})} $$
其中，$p(y=c|\boldsymbol{\theta})$ 代表各类别的先验概率；$p(\boldsymbol{x}|y=c,\boldsymbol{\theta})$ 是类别 $c$ 的**类条件密度**(class-conditional density)，被视为模型参数；$p(\boldsymbol{x}|\boldsymbol{\theta})=\sum_{c'}p(\boldsymbol{x}|y=c',\boldsymbol{\theta})p(y=c'|\boldsymbol{\theta})$ 是归一化因子。

由于此模型可通过由 $p(\boldsymbol{x}|y=c,\boldsymbol{\theta})$ 采样，为特征 $\boldsymbol{x}$ 生成类别，故称之为**生成分类器**(generative classifier)。

一般而言，假设训练集中的样本都是独立同分布的，由大数定律可知，当训练集较大时，即可用各类样本出现的频率估计 $p(y=c|\boldsymbol{\theta})$ 。同时，$p(\boldsymbol{x}|\boldsymbol{\theta})$ 与类别无关。所以，此模型的重点问题就是如何通过训练数据估计类条件密度 $p(\boldsymbol{x}|y=c,\boldsymbol{\theta})$ 。

对于类条件概率 $p(\boldsymbol{x}|y=c,\boldsymbol{\theta})$ 而言，则一般不能直接根据样本出现的频率来估计。因为样本属性的取值有可能是连续的，其取值空间是无限的。即使将其分段截取，或本来就只能取离散值，其取值空间的大小也是呈指数增长的，往往远大于训练样本数量。也就是说，很多样本取值在训练集中根本没有出现，直接使用频率来估计 P(x I c) 显然不可行，因为"未被观测到"与"出现概率为零"通常是不同的.

### 估计

