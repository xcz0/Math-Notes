# 分类器

从概率视角，分类器即是在已知样本特征 $x$ 下，找到特定的类别 $c$ ，使得 $p(y=c|\boldsymbol{x},\boldsymbol{\theta})$ 最大，从而将此样本分类为 $c$ 。根据 $p(y=c|\boldsymbol{x},\boldsymbol{\theta})$ 不同的确定方式，分类器也分为两种：

## 判别分类器

若直接通过训练数据确定 $p(y|x,\theta)$，则称之为**判别分类器**(discriminative classifier)。

## 生成分类器

根据Bayes公式，将 $p(y=c|\boldsymbol{x},\boldsymbol{\theta})$ 拆解为：
$$ p(y=c|\boldsymbol{x},\boldsymbol{\theta})=\frac{p(\boldsymbol{x}|y=c,\boldsymbol{\theta})p(y=c|\boldsymbol{\theta})}{\sum_{c'}p(\boldsymbol{x}|y=c',\boldsymbol{\theta})p(y=c'|\boldsymbol{\theta})} $$
其中，$p(y=c|\boldsymbol{\theta})$ 代表各类别的先验概率；$p(\boldsymbol{x}|y=c,\boldsymbol{\theta})$ 是类别 $c$ 的**类条件密度**(class-conditional density)，被视为模型参数；$p(\boldsymbol{x}|\boldsymbol{\theta})=\sum_{c'}p(\boldsymbol{x}|y=c',\boldsymbol{\theta})p(y=c'|\boldsymbol{\theta})$ 是归一化因子。

一般而言，假设训练集中的样本都是独立同分布的，由大数定律可知，可用各类样本出现的频率估计 $p(y=c|\boldsymbol{\theta})$ 。同时，$p(\boldsymbol{x}|\boldsymbol{\theta})$ 与类别无关。所以，此模型的重点问题就是如何通过训练数据估计类条件密度 $p(\boldsymbol{x}|y=c,\boldsymbol{\theta})$ 。

由于此模型可通过由 $p(\boldsymbol{x}|y=c,\boldsymbol{\theta})$ 采样，为特征 $\boldsymbol{x}$ 生成类别，故称之为**生成分类器**(generative classifier)。