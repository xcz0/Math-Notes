# 统计学习

## 统计学习的定义

> 如果一个系统能够通过执行某个过程改进它的性能，这就是学习。

统计学习就是计算机系统通过运用数据及统计方法提高系统性能的机器学习。统计学习研究的对象是数据(data)。统计学习关于数据的基本假设是同类数据具有一定的统计规律性。统计学习用于对数据的预测与分析。总的目标就是考虑学习什么样的模型和如何学习模型。通过构建概率统计模型实现的。具体而言，统计学习是为了寻找输入变量 $X=(X_1, X_2,...,X_p)$ 与输出变量 $Y$ 间的联系而建立的方法。
设
$$ Y=f(X)+\epsilon$$

+ $f$为固定但未知的映射，代表了此输入提供给输出的系统(systematic)信息。
+ $X$是输入变量(input variables)，又称自变量(independnt varible)，预测因素(predictors)，特征(features)  ，有时也直接简称为变量(varible)
+ $Y$是输出变量(output varibles)，又称因变量(dependnt varible)，响应(response)  
+ $\epsilon$是误差项(error term)，与自变量 $X$ 独立，且期望为0 $E(\epsilon)=0$  

### 统计学习的研究

+ 统计学习方法：在开发新的学习方法；
+ 统计学习理论：探求统计学习方法的有效性与效率，以及统计学习的基本理论问题；
+ 统计学习应用：将统计学习方法应用到实际问题中去，解决实际问题。

统计学习即一系列估计$f$的方法。

### 为什么估计$f$

主要有两大理由，一个是预测(prediction)，一个是推断(inference)

#### 预测

在许多情况下，一组输入$X$是现成的，但输出$Y$不容易得到。由于误差项期望为0，所以可采用
$$\hat{Y}=\hat{f}(X)$$
预测$Y$，其中$\hat{f}$代表对$f$的预测，$\hat{Y}$代表对$Y$的预测。在预测过程中，$\hat{f}$常被视为一个**黑箱**(black box)。此时$\hat{f}$的确切形式不重要，只注重它关于$Y$的预测$\hat{Y}$的准确度。

作为对$Y$的预测，$\hat{Y}$的精度取决于两个量：**可约误差**(reducible error)和**不可约误差**(irreducible error)。可约误差来源于$\hat{f}$与真实的$f$之间的差异，可以通过使用更适合的统计学习技术改进。不可约误差来源于$\epsilon$的随机性，无论如何改进方法，都不能减少这部分误差。

若假设$\hat{f}$与$X$都是固定的，即只有$\epsilon$具有随机性，那么
$$\begin{aligned}
E(Y-\hat{Y})^2=&E[f(X)+\epsilon-\hat{f}(X)]^2 \\
& [f(X)-\hat{f}(X)]^2+\Var(\epsilon)
\end{aligned}$$
其中$E(Y-\hat{Y})^2$代表均方误差的期望值，$Var(\epsilon)$代表误差项的方差，即均方误差=可约误差+不可约误差。而好的预测就是要尽可能地减小可约误差。

#### 推断

推断主要关心$Y$与$X$间的联系。$\hat{f}$不能被视为一个黑箱，此时主要关系$\hat{f}$的确切形式。具体而言，需要回答以下三个问题：

1. 哪些自变量与因变量是相关的？各自变量对响应的影响程度
2. 因变量与每一个自变量的关系是什么样的？
3. 因变量与每一个自变量能否用线性等式或者其他更复杂的等式充分表示？

### 如何估计$f$

假设我们观察到了一组n个不同的数据点。这些观测值被称为训练数据(training data)，因为我们将使用这些观测值来训练或教导我们的方法如何估计 $f$ 。将第$i$个观测值的第$j$个特征记为$x_{i,j}$；第$i$个观测值的响应记为$y_i$。

#### 参数方法



#### 非参数方法



### 预测准确性VS模型解释性

![[flexibility vs inter pretability.png]]

一些模型是受限制的(restrictive)，在相对小的范围内估计 $f$，比如线性模型；还有一些模型是比较灵活的(flexible)，比如非参数方法。灵活的模型往往具有更好的预测准确性(prediction Accuracy)。那么为什么还要使用受限制的模型，而不都使用灵活的模型呢？因为灵活的模型往往模型解释性(Model Interpretability)差。只知道预测结果是好的，但是不知道为什么好。而一些受限制的模型，比如线性模型，其中的参数都是具有解释意义的，可以帮助更好地理解自变量与因变量之间的关系。所以，如果单单只是预测的话，可以用灵活的模型；如果是为了推断的话，那么就需要一些解释性强的，较为受限的模型。

但由于复杂模型很可能过拟合，有时使用相对受限的模型反而可以获得更好的预测效果。

### 监督 VS 非监督

大多数统计学习算法可以分为以下两类：[[监督学习]] (supervised learning)和 [[无监督学习]] (unsupervised learning)  

监督学习指的是：给定一个观测值 $x_i$，就有相应的 $y_i$ 与之对应。监督学习希望找到一个模型联系起自变量 $X$ 和因变量 $Y$，以进行预测或者评估。

非监督学习指的是：给定一个观测值 $x_i$，没有相应的 $y_i$ 与之对应。非监督学习缺少因变量来监督分析，关注的是自变量之间的关系，常见的方法是聚类分析(cluster analysis)。

半监督学习(semi-supervised learning)：部分观测值有对应的响应，部分没有。

### 回归 VS 分类

变量可以分为定量的(quantitative)和定性的(qualitative)。定量的变量值是数字型(numerical)，比如人的身高，体重，收入，都是定量的。定性的变量是不同的类(class)，比如人的性别。  
当问题的因变量是定量的，此类问题就是回归问题(regression)；当问题的因变量是定性的，此类问题就是分类问题(classification)

## 模型的评估

统计学习中，有一条没有免费午餐定理：没有哪一个方法可以对任何数据集，都胜过其他任何方法。所以，在具体实践中，选择最好的方法，成为了一个具有挑战性的问题。但是在某个特定的数据集中，要如何比较模型的好坏呢？以下就介绍了一些评估模型好坏的概念。

### 训练误差与测试误差

训练误差和测试误差是模型关于数据集的平均损失。

提到一句， 统计学习方法具体采用的损失函数未必是评估时使用的损失函数，这句理解下。参考下在数据科学比赛中给出的评分标准，与实际学习采用的损失函数之间的关系。

### 测量拟合优度

为了评估统计学习方法在给定数据集上的性能，我们需要一些方法来衡量其预测与实际观测数据的匹配程度。也就是说，我们需要量化给定观测的预测响应值与该观测的真实响应值接近的程度。回归模型中，最常用的是均方误差(mean squared error, MSE)
$$ \text{MSE}=\frac{1}{n} \sum_{i=1}^{n}[y_i-\hat{f}(x_{i})]^2 $$

MSE分为训练MSE(training MSE)和测试MSE(test MSE)。顾名思义，训练MSE，是用训练集计算产生的MSE，测试MSE，是用测试集计算产生的MSE。通常，我们更希望获得较小的测试MSE，而不是较小的训练MSE，因为我们希望该模型在未被检测到的数据上，也能产生好的效果。所以，通常我们更青睐于使得测试MSE最小的模型。  

需要注意的是，训练MSE和测试MSE看似关系密切，但其实不然：较小的训练MSE并不能保证较小的测试MSE。所以，那些训练MSE较小的模型，未必就有较小的测试MSE。  

在实践中，训练MSE是容易计算的，而测试MSE往往比较困难计算。交叉验证(cross-validation)就是一类用来评估测试MSE的方法。

## 偏差 VS 方差

在测试MSE曲线中观察到的U形趋势是统计学习方法的两个竞争属性的结果。测试MSE的方差，可以由如下三部分组成：
$$ \begin{aligned}
E[Y-\hat{f}(X)]^2=& E\{E[Y-\hat{f}(X)]^2|X\} \\
=& E[f(X)-\hat{f}(X)]^2+\Var(\epsilon) \\
=& \Var(\hat{f}(X))+ \left[ E(\hat{f}(X)-f(X))\right] ^{2}+Var(\epsilon)
\end{aligned}
$$
其中$Var(\epsilon)$是不可约误差，是测试MSE的下界，主要关心的是$\hat{f}(X)$的偏差(bias)和方差(variance)。所以为了让测试MSE尽可能的小，我们希望让$\hat{f}(X)$的偏差和方差尽可能的小。

注意，$\hat{f}$是由训练数据得出的结果。若将训练数据视为随机的，$\hat{f}$一样是随机的，即$\hat{f}(X)$的随机性即来源于训练数据，也来源于测试数据。对于特定的测试数据集，方差代表了当训练数据变动时，$\hat{f}(X)$的变动情况。一般而言，更复杂的统计方法有着更高的方差。

但是很遗憾，这两者往往是相互制约的关系：较小的偏差意味着较大的方差；较小的方差意味着较大的偏差。因此这就需要在较小的偏差和较小的方差之间，进行权衡(trade-off)。

## 机器学习与常规程序的特点

+ 常规程序：由人主动设定完成任务的所需要的步骤，显式地写出所有需要的参数和分支可能。适用于处理“简单”的问题，需要程序输入输出间有明确的逻辑关系。

+ 机器学习：人仅仅给出程序框架，程序根据输入的训练数据得出其中的最佳参数，形成程序模型。适用于输入与输出间的逻辑关系复杂且不明确的问题，如图像识别、自然语言处理等。

## 机器学习基本步骤

1. 设定学习框架
2. 定义学习效果的度量方式（损失函数）
3. 输入训练数据集，使用优化算法寻找合适的参数
4. 输入测试数据集，观察学习效果，改进框架或损失函数的设定
5. 重复3，4步，直至得出满意结果